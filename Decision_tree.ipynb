{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the dataset...\n",
      "Dataset loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Load your dataset into a Pandas DataFrame\n",
    "print(\"Loading the dataset...\")\n",
    "df1 = pd.read_csv('Amazon Customer Behavior Survey.csv')\n",
    "# Remove missing values\n",
    "df = df1.dropna()\n",
    "\n",
    "# Deleting rows where 'Age' is less than 18\n",
    "deleted_rows = df[df['age'] < 18]\n",
    "df = df[df['age'] >= 18]\n",
    "print(\"Dataset loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with NaN values:\n",
      "Empty DataFrame\n",
      "Columns: [Timestamp, age, Gender, Purchase_Frequency, Purchase_Categories, Personalized_Recommendation_Frequency, Browsing_Frequency, Product_Search_Method, Search_Result_Exploration, Customer_Reviews_Importance, Add_to_Cart_Browsing, Cart_Completion_Frequency, Cart_Abandonment_Factors, Saveforlater_Frequency, Review_Left, Review_Reliability, Review_Helpfulness, Personalized_Recommendation_Frequency , Recommendation_Helpfulness, Rating_Accuracy , Shopping_Satisfaction, Service_Appreciation, Improvement_Areas]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create a mask for NaN values\n",
    "nan_mask = df.isna()\n",
    "\n",
    "# Filter the DataFrame to show only rows with NaN values\n",
    "nan_rows = df[nan_mask.any(axis=1)]\n",
    "\n",
    "# Print the rows with NaN values\n",
    "print(\"Rows with NaN values:\")\n",
    "print(nan_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding categorical variables...\n",
      "Categorical variables encoded.\n"
     ]
    }
   ],
   "source": [
    "# Encoding categorical variables (convert Gender to numerical)\n",
    "print(\"Encoding categorical variables...\")\n",
    "# Assuming 'df' is your DataFrame\n",
    "df = df[(df['Gender'] != 'Others') & (df['Gender'] != 'Prefer not to say')]\n",
    "\n",
    "# Assuming 'df' is your DataFrame and 'Gender' column contains these values\n",
    "gender_mapping = {'Male': 0, 'Female': 1}\n",
    "\n",
    "# Mapping the genders in the 'Gender' column using the provided mapping\n",
    "df['Gender'] = df['Gender'].map(gender_mapping)\n",
    "print(\"Categorical variables encoded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Separating features and target variable...\n",
      "Features and target variable separated.\n",
      "Splitting the dataset into train and test sets...\n",
      "Dataset split completed.\n",
      "Creating a decision tree classifier...\n",
      "Decision tree classifier created and fitted.\n",
      "Defining parameters to tune...\n",
      "Parameters defined.\n",
      "Finding the best parameters using GridSearchCV...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found using GridSearchCV.\n",
      "Getting the best parameters and fitting the model...\n",
      "Model fitted with the best parameters.\n",
      "Predicting on the test set...\n",
      "Prediction completed.\n",
      "Calculating accuracy...\n",
      "Accuracy of the tuned decision tree classifier: 24.74%\n"
     ]
    }
   ],
   "source": [
    "# Function to map purchase frequency to a numeric value\n",
    "def map_purchase_frequency(freq):\n",
    "    mapping = {\n",
    "        \"Multiple times a week\": 5,\n",
    "        \"Once a week\": 4,\n",
    "        \"Few times a month\": 3,\n",
    "        \"Once a month\": 2,\n",
    "        \"Less than once a month\": 1\n",
    "    }\n",
    "    return mapping.get(freq, 0)\n",
    "\n",
    "# Apply the mapping to the dataframe\n",
    "df['Purchase_Frequency_Num'] = df['Purchase_Frequency'].apply(map_purchase_frequency)\n",
    "print(\"Separating features and target variable...\")\n",
    "X = df[['age', 'Gender']]\n",
    "y = df['Purchase_Categories']\n",
    "print(\"Features and target variable separated.\")\n",
    "\n",
    "# Splitting the dataset into train and test sets\n",
    "print(\"Splitting the dataset into train and test sets...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(\"Dataset split completed.\")\n",
    "\n",
    "# Creating a decision tree classifier\n",
    "print(\"Creating a decision tree classifier...\")\n",
    "dt_classifier = DecisionTreeClassifier()\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "print(\"Decision tree classifier created and fitted.\")\n",
    "\n",
    "# Parameters to tune\n",
    "print(\"Defining parameters to tune...\")\n",
    "param_grid = {\n",
    "    'max_depth': [15, 16, 17, 18],\n",
    "    'min_samples_split': [15, 16, 17],\n",
    "    'min_samples_leaf': [14, 15, 16]\n",
    "}\n",
    "print(\"Parameters defined.\")\n",
    "\n",
    "# Using GridSearchCV to find the best parameters\n",
    "print(\"Finding the best parameters using GridSearchCV...\")\n",
    "grid_search = GridSearchCV(estimator=dt_classifier, param_grid=param_grid, cv=3)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Best parameters found using GridSearchCV.\")\n",
    "\n",
    "# Getting the best parameters and fitting the model\n",
    "print(\"Getting the best parameters and fitting the model...\")\n",
    "best_params = grid_search.best_params_\n",
    "best_dt_classifier = DecisionTreeClassifier(**best_params)\n",
    "best_dt_classifier.fit(X_train, y_train)\n",
    "print(\"Model fitted with the best parameters.\")\n",
    "\n",
    "# Predicting on the test set\n",
    "print(\"Predicting on the test set...\")\n",
    "y_pred = best_dt_classifier.predict(X_test)\n",
    "print(\"Prediction completed.\")\n",
    "\n",
    "# Calculating accuracy\n",
    "print(\"Calculating accuracy...\")\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy of the tuned decision tree classifier: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Separating features and target variable...\n",
      "Features and target variable separated.\n",
      "Splitting the dataset into train and test sets...\n",
      "Dataset split completed.\n",
      "Creating a decision tree classifier...\n",
      "Decision tree classifier created and fitted.\n",
      "Defining parameters to tune...\n",
      "Parameters defined.\n",
      "Finding the best parameters using GridSearchCV...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found using GridSearchCV.\n",
      "Getting the best parameters and fitting the model...\n",
      "Model fitted with the best parameters.\n",
      "Predicting on the test set...\n",
      "Prediction completed.\n",
      "Calculating accuracy...\n",
      "Accuracy of the tuned decision tree classifier: 22.68%\n"
     ]
    }
   ],
   "source": [
    "# Separating features and target variable\n",
    "print(\"Separating features and target variable...\")\n",
    "X = df[['age','Gender']]\n",
    "y = df['Purchase_Categories']\n",
    "print(\"Features and target variable separated.\")\n",
    "\n",
    "# Splitting the dataset into train and test sets\n",
    "print(\"Splitting the dataset into train and test sets...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(\"Dataset split completed.\")\n",
    "\n",
    "# Creating a decision tree classifier\n",
    "print(\"Creating a decision tree classifier...\")\n",
    "dt_classifier = DecisionTreeClassifier()\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "print(\"Decision tree classifier created and fitted.\")\n",
    "\n",
    "# Parameters to tune\n",
    "print(\"Defining parameters to tune...\")\n",
    "param_grid = {\n",
    "    'max_depth': [2, 3, 4, 5],\n",
    "    'min_samples_split': [2, 3, 4],\n",
    "    'min_samples_leaf': [1, 2, 3]\n",
    "}\n",
    "print(\"Parameters defined.\")\n",
    "\n",
    "# Using GridSearchCV to find the best parameters\n",
    "print(\"Finding the best parameters using GridSearchCV...\")\n",
    "grid_search = GridSearchCV(estimator=dt_classifier, param_grid=param_grid, cv=3)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Best parameters found using GridSearchCV.\")\n",
    "\n",
    "# Getting the best parameters and fitting the model\n",
    "print(\"Getting the best parameters and fitting the model...\")\n",
    "best_params = grid_search.best_params_\n",
    "best_dt_classifier = DecisionTreeClassifier(**best_params)\n",
    "best_dt_classifier.fit(X_train, y_train)\n",
    "print(\"Model fitted with the best parameters.\")\n",
    "\n",
    "# Predicting on the test set\n",
    "print(\"Predicting on the test set...\")\n",
    "y_pred = best_dt_classifier.predict(X_test)\n",
    "print(\"Prediction completed.\")\n",
    "\n",
    "# Calculating accuracy\n",
    "print(\"Calculating accuracy...\")\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy of the tuned decision tree classifier: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_25824\\1121116306.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Manually input age and gender\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Enter age: \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mgender\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Enter gender (M/F): \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Encode gender to numerical value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: ''"
     ]
    }
   ],
   "source": [
    "# Input age and gender\n",
    "age = int(input(\"Enter age: \"))\n",
    "gender = input(\"Enter gender (M/F): \")\n",
    "\n",
    "# Encode gender to numerical value\n",
    "gender = 0 if gender.upper() == 'M' else 1\n",
    "\n",
    "# Prediction\n",
    "predicted_category = best_dt_classifier.predict([[age, gender]])\n",
    "\n",
    "print(f\"Based on the input, the predicted purchase category is: {predicted_category[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1: Input - Age: 19, Gender: M, Predicted Purchase Category: Beauty and Personal Care;Clothing and Fashion\n",
      "Test 2: Input - Age: 24, Gender: F, Predicted Purchase Category: Beauty and Personal Care;Clothing and Fashion\n",
      "Test 3: Input - Age: 29, Gender: M, Predicted Purchase Category: Beauty and Personal Care;Clothing and Fashion\n",
      "Test 4: Input - Age: 34, Gender: F, Predicted Purchase Category: Clothing and Fashion\n",
      "Test 5: Input - Age: 39, Gender: M, Predicted Purchase Category: Clothing and Fashion;others\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\chris\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\chris\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\chris\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\chris\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Function to convert gender to numerical value\n",
    "def encode_gender(gender):\n",
    "    return 0 if gender.upper() == 'M' else 1\n",
    "\n",
    "# Run 5 tests with random age and gender inputs\n",
    "for test_number in range(5):\n",
    "    # Generate random age (you can replace this with your input method)\n",
    "    age = 19 + test_number * 5  # Example: Start from 20 and increase by 5 for each test\n",
    "\n",
    "    # Generate random gender (you can replace this with your input method)\n",
    "    gender = 'M' if test_number % 2 == 0 else 'F'  # Example: Alternating between 'M' and 'F'\n",
    "\n",
    "    # Encode gender\n",
    "    encoded_gender = encode_gender(gender)\n",
    "\n",
    "    # Predict purchase category\n",
    "    predicted_category = dt_classifier.predict([[age, encoded_gender]])\n",
    "\n",
    "    # Display input and predicted output\n",
    "    print(f\"Test {test_number + 1}: Input - Age: {age}, Gender: {gender}, Predicted Purchase Category: {predicted_category[0]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
