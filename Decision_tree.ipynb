{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from random import choice\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the dataset...\n",
      "Dataset loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Load your dataset into a Pandas DataFrame\n",
    "print(\"Loading the dataset...\")\n",
    "df1 = pd.read_csv('Amazon Customer Behavior Survey.csv')\n",
    "# Remove missing values\n",
    "df = df1.dropna()\n",
    "\n",
    "# Deleting rows where 'Age' is less than 18\n",
    "deleted_rows = df[df['age'] < 18]\n",
    "df = df[df['age'] >= 18]\n",
    "print(\"Dataset loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with NaN values:\n",
      "Empty DataFrame\n",
      "Columns: [Timestamp, age, Gender, Purchase_Frequency, Purchase_Categories, Personalized_Recommendation_Frequency, Browsing_Frequency, Product_Search_Method, Search_Result_Exploration, Customer_Reviews_Importance, Add_to_Cart_Browsing, Cart_Completion_Frequency, Cart_Abandonment_Factors, Saveforlater_Frequency, Review_Left, Review_Reliability, Review_Helpfulness, Personalized_Recommendation_Frequency , Recommendation_Helpfulness, Rating_Accuracy , Shopping_Satisfaction, Service_Appreciation, Improvement_Areas]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create a mask for NaN values\n",
    "nan_mask = df.isna()\n",
    "\n",
    "# Filter the DataFrame to show only rows with NaN values\n",
    "nan_rows = df[nan_mask.any(axis=1)]\n",
    "\n",
    "# Print the rows with NaN values\n",
    "print(\"Rows with NaN values:\")\n",
    "print(nan_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding categorical variables...\n",
      "Categorical variables encoded.\n"
     ]
    }
   ],
   "source": [
    "# Encoding categorical variables (convert Gender to numerical)\n",
    "print(\"Encoding categorical variables...\")\n",
    "# Assuming 'df' is your DataFrame\n",
    "df = df[(df['Gender'] != 'Others') & (df['Gender'] != 'Prefer not to say')]\n",
    "\n",
    "# Assuming 'df' is your DataFrame and 'Gender' column contains these values\n",
    "gender_mapping = {'Male': 0, 'Female': 1}\n",
    "\n",
    "# Mapping the genders in the 'Gender' column using the provided mapping\n",
    "df['Gender'] = df['Gender'].map(gender_mapping)\n",
    "print(\"Categorical variables encoded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Separating features and target variable...\n",
      "Features and target variable separated.\n",
      "Splitting the dataset into train and test sets...\n",
      "Dataset split completed.\n",
      "Creating a decision tree classifier...\n",
      "Decision tree classifier created and fitted.\n",
      "Defining parameters to tune...\n",
      "Parameters defined.\n",
      "Finding the best parameters using GridSearchCV...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found using GridSearchCV.\n",
      "Getting the best parameters and fitting the model...\n",
      "Model fitted with the best parameters.\n",
      "Predicting on the test set...\n",
      "Prediction completed.\n",
      "Calculating accuracy...\n",
      "Accuracy of the tuned decision tree classifier: 24.74%\n"
     ]
    }
   ],
   "source": [
    "# Function to map purchase frequency to a numeric value\n",
    "def map_purchase_frequency(freq):\n",
    "    mapping = {\n",
    "        \"Multiple times a week\": 5,\n",
    "        \"Once a week\": 4,\n",
    "        \"Few times a month\": 3,\n",
    "        \"Once a month\": 2,\n",
    "        \"Less than once a month\": 1\n",
    "    }\n",
    "    return mapping.get(freq, 0)\n",
    "\n",
    "# Apply the mapping to the dataframe\n",
    "df['Purchase_Frequency_Num'] = df['Purchase_Frequency'].apply(map_purchase_frequency)\n",
    "print(\"Separating features and target variable...\")\n",
    "X = df[['age', 'Gender']]\n",
    "y = df['Purchase_Categories']\n",
    "print(\"Features and target variable separated.\")\n",
    "\n",
    "# Splitting the dataset into train and test sets\n",
    "print(\"Splitting the dataset into train and test sets...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(\"Dataset split completed.\")\n",
    "\n",
    "# Creating a decision tree classifier\n",
    "print(\"Creating a decision tree classifier...\")\n",
    "dt_classifier = DecisionTreeClassifier()\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "print(\"Decision tree classifier created and fitted.\")\n",
    "\n",
    "# Parameters to tune\n",
    "print(\"Defining parameters to tune...\")\n",
    "param_grid = {\n",
    "    'max_depth': [15, 16, 17, 18],\n",
    "    'min_samples_split': [15, 16, 17],\n",
    "    'min_samples_leaf': [14, 15, 16]\n",
    "}\n",
    "print(\"Parameters defined.\")\n",
    "\n",
    "# Using GridSearchCV to find the best parameters\n",
    "print(\"Finding the best parameters using GridSearchCV...\")\n",
    "grid_search = GridSearchCV(estimator=dt_classifier, param_grid=param_grid, cv=3)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Best parameters found using GridSearchCV.\")\n",
    "\n",
    "# Getting the best parameters and fitting the model\n",
    "print(\"Getting the best parameters and fitting the model...\")\n",
    "best_params = grid_search.best_params_\n",
    "best_dt_classifier = DecisionTreeClassifier(**best_params)\n",
    "best_dt_classifier.fit(X_train, y_train)\n",
    "print(\"Model fitted with the best parameters.\")\n",
    "\n",
    "# Predicting on the test set\n",
    "print(\"Predicting on the test set...\")\n",
    "y_pred = best_dt_classifier.predict(X_test)\n",
    "print(\"Prediction completed.\")\n",
    "\n",
    "# Calculating accuracy\n",
    "print(\"Calculating accuracy...\")\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy of the tuned decision tree classifier: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Separating features and target variable...\n",
      "Features and target variable separated.\n",
      "Splitting the dataset into train and test sets...\n",
      "Dataset split completed.\n",
      "Creating a decision tree classifier...\n",
      "Decision tree classifier created and fitted.\n",
      "Defining parameters to tune...\n",
      "Parameters defined.\n",
      "Finding the best parameters using GridSearchCV...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found using GridSearchCV.\n",
      "Getting the best parameters and fitting the model...\n",
      "Model fitted with the best parameters.\n",
      "Predicting on the test set...\n",
      "Prediction completed.\n",
      "Calculating accuracy...\n",
      "Accuracy of the tuned decision tree classifier: 22.68%\n"
     ]
    }
   ],
   "source": [
    "# Separating features and target variable\n",
    "print(\"Separating features and target variable...\")\n",
    "X = df[['age','Gender']]\n",
    "y = df['Purchase_Categories']\n",
    "print(\"Features and target variable separated.\")\n",
    "\n",
    "# Splitting the dataset into train and test sets\n",
    "print(\"Splitting the dataset into train and test sets...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(\"Dataset split completed.\")\n",
    "\n",
    "# Creating a decision tree classifier\n",
    "print(\"Creating a decision tree classifier...\")\n",
    "dt_classifier = DecisionTreeClassifier()\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "print(\"Decision tree classifier created and fitted.\")\n",
    "\n",
    "# Parameters to tune\n",
    "print(\"Defining parameters to tune...\")\n",
    "param_grid = {\n",
    "    'max_depth': [2, 3, 4, 5],\n",
    "    'min_samples_split': [2, 3, 4],\n",
    "    'min_samples_leaf': [1, 2, 3]\n",
    "}\n",
    "print(\"Parameters defined.\")\n",
    "\n",
    "# Using GridSearchCV to find the best parameters\n",
    "print(\"Finding the best parameters using GridSearchCV...\")\n",
    "grid_search = GridSearchCV(estimator=dt_classifier, param_grid=param_grid, cv=3)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Best parameters found using GridSearchCV.\")\n",
    "\n",
    "# Getting the best parameters and fitting the model\n",
    "print(\"Getting the best parameters and fitting the model...\")\n",
    "best_params = grid_search.best_params_\n",
    "best_dt_classifier = DecisionTreeClassifier(**best_params)\n",
    "best_dt_classifier.fit(X_train, y_train)\n",
    "print(\"Model fitted with the best parameters.\")\n",
    "\n",
    "# Predicting on the test set\n",
    "print(\"Predicting on the test set...\")\n",
    "y_pred = best_dt_classifier.predict(X_test)\n",
    "print(\"Prediction completed.\")\n",
    "\n",
    "# Calculating accuracy\n",
    "print(\"Calculating accuracy...\")\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy of the tuned decision tree classifier: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6348\\251655345.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Input age and gender\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Enter age: \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mgender\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Enter gender (M/F): \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Encode gender to numerical value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: ''"
     ]
    }
   ],
   "source": [
    "# Input age and gender\n",
    "age = int(input(\"Enter age: \"))\n",
    "gender = input(\"Enter gender (M/F): \")\n",
    "\n",
    "# Encode gender to numerical value\n",
    "gender = 0 if gender.upper() == 'M' else 1\n",
    "\n",
    "# Prediction\n",
    "predicted_category = best_dt_classifier.predict([[age, gender]])\n",
    "\n",
    "print(f\"Based on the input, the predicted purchase category is: {predicted_category[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the tuned decision tree classifier: 0.00%\n",
      "Test 1: Input - Age: 20, Gender (Encoded): 1, Purchase Category: Groceries and Gourmet Food;Beauty and Personal Care;Clothing and Fashion;Home and Kitchen, Predicted Purchase Frequency: Multiple times a week\n",
      "Test 2: Input - Age: 25, Gender (Encoded): 0, Purchase Category: Beauty and Personal Care;Home and Kitchen;others, Predicted Purchase Frequency: Once a week\n",
      "Test 3: Input - Age: 30, Gender (Encoded): 1, Purchase Category: Groceries and Gourmet Food;Clothing and Fashion;others, Predicted Purchase Frequency: Few times a month\n",
      "Test 4: Input - Age: 35, Gender (Encoded): 0, Purchase Category: Groceries and Gourmet Food;Home and Kitchen;others, Predicted Purchase Frequency: Less than once a month\n",
      "Test 5: Input - Age: 40, Gender (Encoded): 1, Purchase Category: Beauty and Personal Care;others, Predicted Purchase Frequency: Once a month\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\chris\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\chris\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\chris\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\chris\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Drop rows where 'Gender' is 'Others' or 'Prefer not to say'\n",
    "df = df[(df['Gender'] != 'Others') & (df['Gender'] != 'Prefer not to say')]\n",
    "\n",
    "# Encoding categorical variables using LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df['Gender'] = le.fit_transform(df['Gender'])\n",
    "df['Purchase_Categories'] = le.fit_transform(df['Purchase_Categories'])\n",
    "\n",
    "# Separating features and target variable\n",
    "X = df[['age', 'Gender', 'Purchase_Categories']]\n",
    "y = df['Purchase_Frequency']\n",
    "\n",
    "# Splitting the dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Assuming 'dt_classifier' is your Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier()\n",
    "\n",
    "# Fit the classifier with training data\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy of the tuned decision tree classifier: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Run 5 tests with random age, gender, and purchase category inputs\n",
    "for test_number in range(5):\n",
    "    # Generate random age (you can replace this with your input method)\n",
    "    age = 20 + test_number * 5  # Example: Start from 20 and increase by 5 for each test\n",
    "\n",
    "    # Generate random gender (you can replace this with your input method)\n",
    "    gender = choice([0, 1])  # Randomly choose 0 or 1, encoded values for 'Male' and 'Female'\n",
    "    \n",
    "    # Generate random purchase category (you can replace this with your input method)\n",
    "    purchase_category = choice(df['Purchase_Categories'].unique())  # Randomly select from unique categories\n",
    "    \n",
    "    # Predict purchase frequency using the trained Decision Tree Classifier\n",
    "    predicted_purchase_frequency = dt_classifier.predict([[age, gender, purchase_category]])\n",
    "\n",
    "    # Display input and predicted output\n",
    "    print(f\"Test {test_number + 1}: Input - Age: {age}, Gender (Encoded): {gender}, Purchase Category: {le.inverse_transform([purchase_category])[0]}, Predicted Purchase Frequency: {predicted_purchase_frequency[0]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
